{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1efd1f50",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa00e50c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matthewli125/miniconda3/envs/autoboltagent/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/matthewli125/miniconda3/envs/autoboltagent/lib/python3.10/site-packages/ufl/__init__.py:250: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    }
   ],
   "source": [
    "from autoboltagent import verbose_prompts, grammars\n",
    "from autoboltagent  import prompts\n",
    "from autoboltagent.verbose_agents import VerboseLowFidelityAgent\n",
    "from autoboltagent.agents import LowFidelityAgent\n",
    "from autoboltagent.tools.logger import AgentLogger\n",
    "from autoboltagent.VLLMModelCustom import VLLMModelCustom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85dcc950",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vllm import SamplingParams\n",
    "from vllm.sampling_params import StructuredOutputsParams\n",
    "import smolagents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb89c141",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87e3fec",
   "metadata": {},
   "source": [
    "### set up logger and db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c84a2a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_url = \"sqlite:///../src/agent_logs_grammar_prod.db\"\n",
    "logger = AgentLogger(db_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00aa648",
   "metadata": {},
   "source": [
    "### params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "653c34d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_configuration = {\n",
    "    \"load\": 60000,\n",
    "    \"desired_safety_factor\": 3.0,\n",
    "    \"bolt_yield_strength\": 940,\n",
    "    \"plate_yield_strength\": 250,\n",
    "    \"preload\": 150000,\n",
    "    \"pitch\": 1.5,\n",
    "    \"plate_thickness\": 10,\n",
    "    \"bolt_elastic_modulus\": 210,\n",
    "    \"plate_elastic_modulus\": 210\n",
    "    }\n",
    "\n",
    "input = \"\"\"{\n",
    "    \"load\": 60000,\n",
    "    \"desired_safety_factor\": 3.0,\n",
    "    \"bolt_yield_strength\": 940,\n",
    "    \"plate_yield_strength\": 250,\n",
    "    \"preload\": 150000,\n",
    "    \"pitch\": 1.5,\n",
    "    \"plate_thickness\": 10,\n",
    "    \"bolt_elastic_modulus\": 210,\n",
    "    \"plate_elastic_modulus\": 210\n",
    "    }\"\"\"\n",
    "\n",
    "grammar_sop = StructuredOutputsParams(\n",
    "    grammar=grammars.low_fidelity_agent_grammar_debug\n",
    ")\n",
    "\n",
    "sampling_params = SamplingParams(\n",
    "    max_tokens=200,\n",
    "    temperature=0.0,\n",
    "    structured_outputs=grammar_sop\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f17629d",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e3c23e",
   "metadata": {},
   "source": [
    "### Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4143950e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 01-29 21:24:13 [utils.py:263] non-default args: {'gpu_memory_utilization': 0.85, 'disable_log_stats': True, 'model': 'RedHatAI/Qwen2.5-3B-Instruct-quantized.w8a8'}\n",
      "INFO 01-29 21:24:14 [model.py:530] Resolved architecture: Qwen2ForCausalLM\n",
      "INFO 01-29 21:24:14 [model.py:1545] Using max model len 32768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-29 21:24:15,764\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 01-29 21:24:15 [scheduler.py:229] Chunked prefill is enabled with max_num_batched_tokens=8192.\n",
      "INFO 01-29 21:24:15 [vllm.py:630] Asynchronous scheduling is enabled.\n",
      "INFO 01-29 21:24:15 [vllm.py:637] Disabling NCCL for DP synchronization when using async scheduling.\n",
      "WARNING 01-29 21:24:16 [interface.py:470] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.\n",
      "\u001b[0;36m(EngineCore_DP0 pid=40850)\u001b[0;0m INFO 01-29 21:24:21 [core.py:97] Initializing a V1 LLM engine (v0.14.1) with config: model='RedHatAI/Qwen2.5-3B-Instruct-quantized.w8a8', speculative_config=None, tokenizer='RedHatAI/Qwen2.5-3B-Instruct-quantized.w8a8', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=32768, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=compressed-tensors, enforce_eager=False, enable_return_routed_experts=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01, cudagraph_metrics=False, enable_layerwise_nvtx_tracing=False, enable_mfu_metrics=False, enable_mm_processor_stats=False, enable_logging_iteration_details=False), seed=0, served_model_name=RedHatAI/Qwen2.5-3B-Instruct-quantized.w8a8, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'compile_ranges_split_points': [8192], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 512, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>, 'evaluate_guards': False, 'assume_32_bit_indexing': True}, 'local_cache_dir': None}\n",
      "\u001b[0;36m(EngineCore_DP0 pid=40850)\u001b[0;0m INFO 01-29 21:24:21 [parallel_state.py:1214] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://172.24.215.16:51509 backend=nccl\n",
      "\u001b[0;36m(EngineCore_DP0 pid=40850)\u001b[0;0m INFO 01-29 21:24:23 [parallel_state.py:1425] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank N/A\n",
      "\u001b[0;36m(EngineCore_DP0 pid=40850)\u001b[0;0m WARNING 01-29 21:24:23 [interface.py:470] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.\n",
      "\u001b[0;36m(EngineCore_DP0 pid=40850)\u001b[0;0m INFO 01-29 21:24:23 [gpu_model_runner.py:3808] Starting to load model RedHatAI/Qwen2.5-3B-Instruct-quantized.w8a8...\n",
      "\u001b[0;36m(EngineCore_DP0 pid=40850)\u001b[0;0m INFO 01-29 21:24:23 [compressed_tensors_w8a8_int8.py:62] Using CutlassScaledMMLinearKernel for CompressedTensorsW8A8Int8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0;36m(EngineCore_DP0 pid=40850)\u001b[0;0m /home/matthewli125/miniconda3/envs/autoboltagent/lib/python3.10/site-packages/tvm_ffi/_optional_torch_c_dlpack.py:174: UserWarning: Failed to JIT torch c dlpack extension, EnvTensorAllocator will not be enabled.\n",
      "\u001b[0;36m(EngineCore_DP0 pid=40850)\u001b[0;0m We recommend installing via `pip install torch-c-dlpack-ext`\n",
      "\u001b[0;36m(EngineCore_DP0 pid=40850)\u001b[0;0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;36m(EngineCore_DP0 pid=40850)\u001b[0;0m INFO 01-29 21:24:25 [cuda.py:351] Using FLASH_ATTN attention backend out of potential backends: ('FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION')\n",
      "\u001b[0;36m(EngineCore_DP0 pid=40850)\u001b[0;0m INFO 01-29 21:24:25 [weight_utils.py:550] No model.safetensors.index.json found in remote.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.82it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.82it/s]\n",
      "\u001b[0;36m(EngineCore_DP0 pid=40850)\u001b[0;0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;36m(EngineCore_DP0 pid=40850)\u001b[0;0m INFO 01-29 21:24:26 [default_loader.py:291] Loading weights took 0.65 seconds\n",
      "\u001b[0;36m(EngineCore_DP0 pid=40850)\u001b[0;0m INFO 01-29 21:24:26 [gpu_model_runner.py:3905] Model loading took 3.23 GiB memory and 2.647831 seconds\n",
      "\u001b[0;36m(EngineCore_DP0 pid=40850)\u001b[0;0m INFO 01-29 21:24:31 [backends.py:644] Using cache directory: /home/matthewli125/.cache/vllm/torch_compile_cache/fec4a759af/rank_0_0/backbone for vLLM's torch.compile\n",
      "\u001b[0;36m(EngineCore_DP0 pid=40850)\u001b[0;0m INFO 01-29 21:24:31 [backends.py:704] Dynamo bytecode transform time: 4.86 s\n",
      "\u001b[0;36m(EngineCore_DP0 pid=40850)\u001b[0;0m INFO 01-29 21:24:35 [backends.py:226] Directly load the compiled graph(s) for compile range (1, 8192) from the cache, took 1.314 s\n",
      "\u001b[0;36m(EngineCore_DP0 pid=40850)\u001b[0;0m INFO 01-29 21:24:35 [monitor.py:34] torch.compile takes 6.18 s in total\n",
      "\u001b[0;36m(EngineCore_DP0 pid=40850)\u001b[0;0m INFO 01-29 21:24:36 [gpu_worker.py:358] Available KV cache memory: 2.12 GiB\n",
      "\u001b[0;36m(EngineCore_DP0 pid=40850)\u001b[0;0m INFO 01-29 21:24:36 [kv_cache_utils.py:1305] GPU KV cache size: 61,856 tokens\n",
      "\u001b[0;36m(EngineCore_DP0 pid=40850)\u001b[0;0m INFO 01-29 21:24:36 [kv_cache_utils.py:1310] Maximum concurrency for 32,768 tokens per request: 1.89x\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 51/51 [00:02<00:00, 19.89it/s]\n",
      "Capturing CUDA graphs (decode, FULL): 100%|██████████| 35/35 [00:01<00:00, 27.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;36m(EngineCore_DP0 pid=40850)\u001b[0;0m INFO 01-29 21:24:40 [gpu_model_runner.py:4856] Graph capturing finished in 4 secs, took 0.61 GiB\n",
      "\u001b[0;36m(EngineCore_DP0 pid=40850)\u001b[0;0m INFO 01-29 21:24:40 [core.py:273] init engine (profile, create kv cache, warmup model) took 14.00 seconds\n",
      "\u001b[0;36m(EngineCore_DP0 pid=40850)\u001b[0;0m INFO 01-29 21:24:42 [vllm.py:630] Asynchronous scheduling is enabled.\n",
      "INFO 01-29 21:24:42 [llm.py:347] Supported tasks: ['generate']\n"
     ]
    }
   ],
   "source": [
    "model = smolagents.VLLMModel(\n",
    "    model_id=\"RedHatAI/Qwen2.5-3B-Instruct-quantized.w8a8\",\n",
    "    model_kwargs={\n",
    "        \"gpu_memory_utilization\": 0.85,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cec7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom local VLLM model with grammar\n",
    "\n",
    "model = VLLMModelCustom(\n",
    "        model_id=\"RedHatAI/Qwen2.5-3B-Instruct-quantized.w8a8\",\n",
    "        apply_chat_template_kwargs=None,\n",
    "        model_kwargs={\n",
    "            \"gpu_memory_utilization\": 0.85,\n",
    "        },\n",
    "        sampling_params=sampling_params,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278e5eeb",
   "metadata": {},
   "source": [
    "### Cloud models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9ba947",
   "metadata": {},
   "outputs": [],
   "source": [
    "FIREWORKS_API_KEY = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14fa02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# smolagents InferenceClientModel\n",
    "\n",
    "model = smolagents.InferenceClientModel( # type: ignore\n",
    "    provider=\"fireworks-ai\",\n",
    "    model_id=\"openai/gpt-oss-20b\",\n",
    "    token=FIREWORKS_API_KEY,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fce9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smolagents.OpenAIServerModel(\n",
    "    model_id=\"accounts/fireworks/models/gpt-oss-20b\",\n",
    "    api_base=\"https://api.fireworks.ai/inference/v1\", \n",
    "    api_key=FIREWORKS_API_KEY,\n",
    "    # response_format={\n",
    "    #     \"type\": \"grammar\",\n",
    "    #     \"grammar\": grammars.low_fidelity_agent_grammar_debug\n",
    "    # }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92627081",
   "metadata": {},
   "source": [
    "# Run agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05023b62",
   "metadata": {},
   "source": [
    "### Single agent run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96b94fe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">╭─────────────────────────────────────── </span><span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">New run - VerboseLowFidelityAgent</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ───────────────────────────────────────╮</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">Given the following joint configuration:</span>                                                                        <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">joint_configuration = {</span>                                                                                         <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">    \"load\": 60000,</span>                                                                                              <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">    \"desired_safety_factor\": 3.0,</span>                                                                               <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">    \"bolt_yield_strength\": 940,</span>                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">    \"plate_yield_strength\": 250,</span>                                                                                <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">    \"preload\": 150000,</span>                                                                                          <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">    \"pitch\": 1.5,</span>                                                                                               <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">    \"plate_thickness\": 10,</span>                                                                                      <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">    \"bolt_elastic_modulus\": 210,</span>                                                                                <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">    \"plate_elastic_modulus\": 210</span>                                                                                <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">    }</span>                                                                                                           <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">Determine the optimal number of bolts and the major diameter of the bolts:</span>                                      <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">╰─ VLLMModel - RedHatAI/Qwen2.5-3B-Instruct-quantized.w8a8 ───────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m╭─\u001b[0m\u001b[38;2;212;183;2m──────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m \u001b[0m\u001b[1;38;2;212;183;2mNew run - VerboseLowFidelityAgent\u001b[0m\u001b[38;2;212;183;2m \u001b[0m\u001b[38;2;212;183;2m──────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m─╮\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mGiven the following joint configuration:\u001b[0m                                                                        \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mjoint_configuration = {\u001b[0m                                                                                         \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1m    \"load\": 60000,\u001b[0m                                                                                              \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1m    \"desired_safety_factor\": 3.0,\u001b[0m                                                                               \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1m    \"bolt_yield_strength\": 940,\u001b[0m                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1m    \"plate_yield_strength\": 250,\u001b[0m                                                                                \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1m    \"preload\": 150000,\u001b[0m                                                                                          \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1m    \"pitch\": 1.5,\u001b[0m                                                                                               \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1m    \"plate_thickness\": 10,\u001b[0m                                                                                      \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1m    \"bolt_elastic_modulus\": 210,\u001b[0m                                                                                \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1m    \"plate_elastic_modulus\": 210\u001b[0m                                                                                \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1m    }\u001b[0m                                                                                                           \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mDetermine the optimal number of bolts and the major diameter of the bolts:\u001b[0m                                      \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m╰─\u001b[0m\u001b[38;2;212;183;2m VLLMModel - RedHatAI/Qwen2.5-3B-Instruct-quantized.w8a8 \u001b[0m\u001b[38;2;212;183;2m──────────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m─╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">Step 1</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1;37mStep 1\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding requests: 100%|██████████| 1/1 [00:00<00:00, 134.97it/s]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Step 1: Duration 290.16 seconds]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m[Step 1: Duration 290.16 seconds]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m agent \u001b[38;5;241m=\u001b[39m VerboseLowFidelityAgent(model, joint_configuration, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mverbose low fidelity agent\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mverbose prompts + minimized + reason 512 + gpt 11\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m3.0\u001b[39m, logger, max_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m      2\u001b[0m instruction \u001b[38;5;241m=\u001b[39m verbose_prompts\u001b[38;5;241m.\u001b[39mEXAMPLE_TASK_INSTRUCTIONS\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstruction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/autoboltagent/lib/python3.10/site-packages/smolagents/agents.py:498\u001b[0m, in \u001b[0;36mMultiStepAgent.run\u001b[0;34m(self, task, stream, reset, images, additional_args, max_steps, return_full_result)\u001b[0m\n\u001b[1;32m    495\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_stream(task\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask, max_steps\u001b[38;5;241m=\u001b[39mmax_steps, images\u001b[38;5;241m=\u001b[39mimages)\n\u001b[1;32m    497\u001b[0m run_start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 498\u001b[0m steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;66;03m# Outputs are returned only at the end. We only look at the last step.\u001b[39;00m\n\u001b[1;32m    501\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(steps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], FinalAnswerStep)\n",
      "File \u001b[0;32m~/miniconda3/envs/autoboltagent/lib/python3.10/site-packages/smolagents/agents.py:577\u001b[0m, in \u001b[0;36mMultiStepAgent._run_stream\u001b[0;34m(self, task, max_steps, images)\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mlog_rule(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStep \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_number\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, level\u001b[38;5;241m=\u001b[39mLogLevel\u001b[38;5;241m.\u001b[39mINFO)\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 577\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_step_stream(action_step):\n\u001b[1;32m    578\u001b[0m         \u001b[38;5;66;03m# Yield all\u001b[39;00m\n\u001b[1;32m    579\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m output\n\u001b[1;32m    581\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, ActionOutput) \u001b[38;5;129;01mand\u001b[39;00m output\u001b[38;5;241m.\u001b[39mis_final_answer:\n",
      "File \u001b[0;32m~/miniconda3/envs/autoboltagent/lib/python3.10/site-packages/smolagents/agents.py:1293\u001b[0m, in \u001b[0;36mToolCallingAgent._step_stream\u001b[0;34m(self, memory_step)\u001b[0m\n\u001b[1;32m   1291\u001b[0m     chat_message \u001b[38;5;241m=\u001b[39m agglomerate_stream_deltas(chat_message_stream_deltas)\n\u001b[1;32m   1292\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1293\u001b[0m     chat_message: ChatMessage \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1294\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_messages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstop_sequences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mObservation:\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCalling tools:\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtools_to_call_from\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtools_and_managed_agents\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1297\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1298\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mlog_markdown(\n\u001b[1;32m   1299\u001b[0m         content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(chat_message\u001b[38;5;241m.\u001b[39mcontent \u001b[38;5;129;01mor\u001b[39;00m chat_message\u001b[38;5;241m.\u001b[39mraw \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1300\u001b[0m         title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput message of the LLM:\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1301\u001b[0m         level\u001b[38;5;241m=\u001b[39mLogLevel\u001b[38;5;241m.\u001b[39mDEBUG,\n\u001b[1;32m   1302\u001b[0m     )\n\u001b[1;32m   1304\u001b[0m \u001b[38;5;66;03m# Record model output\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/autoboltagent/lib/python3.10/site-packages/smolagents/models.py:731\u001b[0m, in \u001b[0;36mVLLMModel.generate\u001b[0;34m(self, messages, stop_sequences, response_format, tools_to_call_from, **kwargs)\u001b[0m\n\u001b[1;32m    715\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mapply_chat_template(\n\u001b[1;32m    716\u001b[0m     messages,\n\u001b[1;32m    717\u001b[0m     tools\u001b[38;5;241m=\u001b[39mtools,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    720\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_chat_template_kwargs,\n\u001b[1;32m    721\u001b[0m )\n\u001b[1;32m    723\u001b[0m sampling_params \u001b[38;5;241m=\u001b[39m SamplingParams(\n\u001b[1;32m    724\u001b[0m     n\u001b[38;5;241m=\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m    725\u001b[0m     temperature\u001b[38;5;241m=\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0.0\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    728\u001b[0m     structured_outputs\u001b[38;5;241m=\u001b[39mstructured_outputs,\n\u001b[1;32m    729\u001b[0m )\n\u001b[0;32m--> 731\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    732\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    733\u001b[0m \u001b[43m    \u001b[49m\u001b[43msampling_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msampling_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcompletion_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    735\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    737\u001b[0m output_text \u001b[38;5;241m=\u001b[39m out[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39moutputs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m    738\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stop_sequences \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupports_stop_parameter:\n",
      "File \u001b[0;32m~/miniconda3/envs/autoboltagent/lib/python3.10/site-packages/vllm/entrypoints/llm.py:439\u001b[0m, in \u001b[0;36mLLM.generate\u001b[0;34m(self, prompts, sampling_params, use_tqdm, lora_request, priority)\u001b[0m\n\u001b[1;32m    429\u001b[0m lora_request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_modality_specific_lora_reqs(prompts, lora_request)\n\u001b[1;32m    431\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_and_add_requests(\n\u001b[1;32m    432\u001b[0m     prompts\u001b[38;5;241m=\u001b[39mprompts,\n\u001b[1;32m    433\u001b[0m     params\u001b[38;5;241m=\u001b[39msampling_params,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    436\u001b[0m     priority\u001b[38;5;241m=\u001b[39mpriority,\n\u001b[1;32m    437\u001b[0m )\n\u001b[0;32m--> 439\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43muse_tqdm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_tqdm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_class\u001b[38;5;241m.\u001b[39mvalidate_outputs(outputs, RequestOutput)\n",
      "File \u001b[0;32m~/miniconda3/envs/autoboltagent/lib/python3.10/site-packages/vllm/entrypoints/llm.py:1764\u001b[0m, in \u001b[0;36mLLM._run_engine\u001b[0;34m(self, use_tqdm)\u001b[0m\n\u001b[1;32m   1762\u001b[0m total_out_toks \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   1763\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_engine\u001b[38;5;241m.\u001b[39mhas_unfinished_requests():\n\u001b[0;32m-> 1764\u001b[0m     step_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1765\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m step_outputs:\n\u001b[1;32m   1766\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m output\u001b[38;5;241m.\u001b[39mfinished:\n",
      "File \u001b[0;32m~/miniconda3/envs/autoboltagent/lib/python3.10/site-packages/vllm/v1/engine/llm_engine.py:294\u001b[0m, in \u001b[0;36mLLMEngine.step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;66;03m# 1) Get EngineCoreOutput from the EngineCore.\u001b[39;00m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record_function_or_nullcontext(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllm_engine step: get_output\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 294\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine_core\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;66;03m# 2) Process EngineCoreOutputs.\u001b[39;00m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record_function_or_nullcontext(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllm_engine step: process_outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/envs/autoboltagent/lib/python3.10/site-packages/vllm/v1/engine/core_client.py:719\u001b[0m, in \u001b[0;36mSyncMPClient.get_output\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    715\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_output\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m EngineCoreOutputs:\n\u001b[1;32m    716\u001b[0m     \u001b[38;5;66;03m# If an exception arises in process_outputs_socket task,\u001b[39;00m\n\u001b[1;32m    717\u001b[0m     \u001b[38;5;66;03m# it is forwarded to the outputs_queue so we can raise it\u001b[39;00m\n\u001b[1;32m    718\u001b[0m     \u001b[38;5;66;03m# from this (run_output_handler) task to shut down the server.\u001b[39;00m\n\u001b[0;32m--> 719\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutputs_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    720\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;167;01mException\u001b[39;00m):\n\u001b[1;32m    721\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_exception(outputs) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/autoboltagent/lib/python3.10/queue.py:171\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_qsize():\n\u001b[0;32m--> 171\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnot_empty\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m timeout \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m must be a non-negative number\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/autoboltagent/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR 01-29 21:29:41 [core_client.py:610] Engine core proc EngineCore_DP0 died unexpectedly, shutting down client.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[rank0]:[W129 21:29:41.511292951 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n"
     ]
    }
   ],
   "source": [
    "agent = VerboseLowFidelityAgent(model, joint_configuration, \"verbose low fidelity agent\", f\"verbose prompts + minimized + reason 512 + gpt 11\", 3.0, logger, max_steps=100)\n",
    "instruction = verbose_prompts.EXAMPLE_TASK_INSTRUCTIONS.format(input)\n",
    "agent.run(instruction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4207a92",
   "metadata": {},
   "source": [
    "### Loop agent run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691f9b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,25):\n",
    "        agent = VerboseLowFidelityAgent(model, joint_configuration, \"verbose low fidelity agent\", f\"verbose prompts + minimized + reason 512 + gpt {i}\", 3.0, logger, max_steps=100)\n",
    "        instruction = verbose_prompts.EXAMPLE_TASK_INSTRUCTIONS.format(input)\n",
    "        agent.run(instruction)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autoboltagent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
